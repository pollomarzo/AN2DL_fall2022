{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature extractor selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Settings\n",
        "\n",
        "Import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\markz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.10.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Random seed for reproducibility\n",
        "seed = 45\n",
        "\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Labels\n",
        "LABELS = ['Species1','Species2','Species3','Species4','Species5','Species6','Species7','Species8']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model hyperparameters\n",
        "INPUT_SHAPE = (96, 96, 3)\n",
        "IMAGE_SIZE = (INPUT_SHAPE[0], INPUT_SHAPE[1])\n",
        "\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "\n",
        "NUM_CLASSES = len(LABELS)\n",
        "MODEL_NAME = \"cnn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths\n",
        "DATA_DIR = 'C:\\\\Users\\\\markz\\\\Desktop\\\\ANN_chall_1\\\\training_data_final'\n",
        "\n",
        "PATH = {}\n",
        "PATH['training'] = os.path.join(DATA_DIR, 'training')\n",
        "PATH['validation'] = os.path.join(DATA_DIR, 'validation')\n",
        "PATH['testing'] = os.path.join(DATA_DIR, 'testing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2122 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Constructor\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    height_shift_range=40,\n",
        "    width_shift_range=40,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    brightness_range=[0.7,1.3],\n",
        "    fill_mode='reflect'\n",
        ") \n",
        "\n",
        "# Generator\n",
        "train_gen = train_data_gen.flow_from_directory(\n",
        "    directory=PATH['training'],\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 5.0, 1: 1.0, 2: 1.0, 3: 1.0, 4: 1.0, 5: 3.0, 6: 1.0, 7: 1.3}\n"
          ]
        }
      ],
      "source": [
        "unique, counts = np.unique(train_gen.classes, return_counts=True)\n",
        "rec = dict(zip(unique, counts))\n",
        "\n",
        "max_value = rec[max(rec, key=rec.get)]\n",
        "\n",
        "cw = {}\n",
        "\n",
        "for k in rec.keys():\n",
        "    cw[k] = max_value/rec[k]\n",
        "\n",
        "#print(cw)\n",
        "\n",
        "cw[0] = 5.0\n",
        "for i in range(1,8):\n",
        "    cw[i] = 1.0\n",
        "cw[5] = 3.0\n",
        "cw[7] = 1.3\n",
        "\n",
        "print(cw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 707 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# Constructor\n",
        "valid_data_gen = ImageDataGenerator()\n",
        "\n",
        "# Generator\n",
        "valid_gen = valid_data_gen.flow_from_directory(\n",
        "    directory=PATH['validation'],\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 713 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "# Constructor\n",
        "test_data_gen = ImageDataGenerator()\n",
        "\n",
        "# Generator\n",
        "test_gen = test_data_gen.flow_from_directory(\n",
        "    directory=PATH['testing'],\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode='rgb',\n",
        "    classes=None,\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "LAYERS = [[512],\n",
        "          [256],\n",
        "          [128],\n",
        "          [128,128],\n",
        "          [256,128],\n",
        "          [512,128],\n",
        "          [512,256,128],\n",
        "          [128,256,128]]\n",
        "FREEZE = [0, round(0.3*295), round(0.6*295), round(0.9*295)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use the supernet as feature extractor\n",
        "\n",
        "def train(layers,layers_to_freeze):\n",
        "    pretrained_model= tf.keras.applications.ConvNeXtBase(include_top=False,input_shape=INPUT_SHAPE,weights='imagenet')\n",
        "\n",
        "    MODEL_NAME = 'convnext_base'\n",
        "\n",
        "    pretrained_model.trainable = False\n",
        "\n",
        "    # Rebuild the classifier\n",
        "    inputs = tfk.Input(shape=INPUT_SHAPE)\n",
        "    x = pretrained_model(inputs)\n",
        "    x = tfkl.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    for layer in layers:\n",
        "        x = tfkl.Dense(layer, kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
        "        x = tfkl.Dropout(0.3)(x)\n",
        "        x = tfkl.BatchNormalization()(x)\n",
        "        x = tfkl.ReLU()(x)\n",
        "\n",
        "    outputs = tfkl.Dense(\n",
        "        NUM_CLASSES,\n",
        "        activation='softmax',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed))(x)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
        "\n",
        "    model.get_layer(MODEL_NAME).trainable = True\n",
        "\n",
        "    for i, layer in enumerate(model.get_layer(MODEL_NAME).layers[:layers_to_freeze]):\n",
        "        layer.trainable=False\n",
        "\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=LEARNING_RATE), metrics=['accuracy'])\n",
        "\n",
        "    print('Fitting with layers',layers,'and freeze '+str(layers_to_freeze))\n",
        "\n",
        "    with tf.device(\"/GPU:0\"):\n",
        "        history = model.fit(\n",
        "            x = train_gen,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            epochs = EPOCHS,\n",
        "            validation_data = valid_gen,\n",
        "            class_weight=cw,\n",
        "            verbose=0,\n",
        "            callbacks=[tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=15, restore_best_weights=True),tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=3, min_lr=0.0, min_delta=0.00001)]\n",
        "        ).history\n",
        "\n",
        "    print('Accuracy: '+str(max(history['val_accuracy'])))\n",
        "    \n",
        "    return (layers, layers_to_freeze, max(history['val_accuracy']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting with layers [512] and freeze 0\n",
            "Accuracy: 0.9009901285171509\n",
            "Fitting with layers [512] and freeze 88\n",
            "Accuracy: 0.9193776249885559\n",
            "Fitting with layers [512] and freeze 177\n",
            "Accuracy: 0.8882602453231812\n",
            "Fitting with layers [512] and freeze 266\n",
            "Accuracy: 0.8698726892471313\n",
            "Fitting with layers [256] and freeze 0\n",
            "Accuracy: 0.896746814250946\n",
            "Fitting with layers [256] and freeze 88\n",
            "Accuracy: 0.9236209392547607\n",
            "Fitting with layers [256] and freeze 177\n",
            "Accuracy: 0.8981612324714661\n",
            "Fitting with layers [256] and freeze 266\n",
            "Accuracy: 0.8712871074676514\n",
            "Fitting with layers [128] and freeze 0\n",
            "Accuracy: 0.893917977809906\n",
            "Fitting with layers [128] and freeze 88\n",
            "Accuracy: 0.9278641939163208\n",
            "Fitting with layers [128] and freeze 177\n",
            "Accuracy: 0.8896746635437012\n",
            "Fitting with layers [128] and freeze 266\n",
            "Accuracy: 0.8727015852928162\n",
            "Fitting with layers [128, 128] and freeze 0\n",
            "Accuracy: 0.8783592581748962\n",
            "Fitting with layers [128, 128] and freeze 88\n",
            "Accuracy: 0.9193776249885559\n",
            "Fitting with layers [128, 128] and freeze 177\n",
            "Accuracy: 0.896746814250946\n",
            "Fitting with layers [128, 128] and freeze 266\n",
            "Accuracy: 0.8599717020988464\n",
            "Fitting with layers [256, 128] and freeze 0\n",
            "Accuracy: 0.9024045467376709\n",
            "Fitting with layers [256, 128] and freeze 88\n",
            "Accuracy: 0.9123055338859558\n",
            "Fitting with layers [256, 128] and freeze 177\n",
            "Accuracy: 0.8854314088821411\n",
            "Fitting with layers [256, 128] and freeze 266\n",
            "Accuracy: 0.8599717020988464\n",
            "Fitting with layers [512, 128] and freeze 0\n",
            "Accuracy: 0.8797736763954163\n",
            "Fitting with layers [512, 128] and freeze 88\n",
            "Accuracy: 0.9250353574752808\n",
            "Fitting with layers [512, 128] and freeze 177\n",
            "Accuracy: 0.8896746635437012\n",
            "Fitting with layers [512, 128] and freeze 266\n",
            "Accuracy: 0.8599717020988464\n",
            "Fitting with layers [512, 256, 128] and freeze 0\n",
            "Accuracy: 0.806223452091217\n",
            "Fitting with layers [512, 256, 128] and freeze 88\n",
            "Accuracy: 0.908062219619751\n",
            "Fitting with layers [512, 256, 128] and freeze 177\n",
            "Accuracy: 0.8868458271026611\n",
            "Fitting with layers [512, 256, 128] and freeze 266\n",
            "Accuracy: 0.8628005385398865\n",
            "Fitting with layers [128, 256, 128] and freeze 0\n",
            "Accuracy: 0.7779349088668823\n",
            "Fitting with layers [128, 256, 128] and freeze 88\n",
            "Accuracy: 0.9052333831787109\n",
            "Fitting with layers [128, 256, 128] and freeze 177\n",
            "Accuracy: 0.8854314088821411\n",
            "Fitting with layers [128, 256, 128] and freeze 266\n",
            "Accuracy: 0.8599717020988464\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for l in LAYERS:\n",
        "    for f in FREEZE:\n",
        "        results.append(train(l,f))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "([512], 0, 0.9009901285171509)\n",
            "([512], 88, 0.9193776249885559)\n",
            "([512], 177, 0.8882602453231812)\n",
            "([512], 266, 0.8698726892471313)\n",
            "([256], 0, 0.896746814250946)\n",
            "([256], 88, 0.9236209392547607)\n",
            "([256], 177, 0.8981612324714661)\n",
            "([256], 266, 0.8712871074676514)\n",
            "([128], 0, 0.893917977809906)\n",
            "([128], 88, 0.9278641939163208)\n",
            "([128], 177, 0.8896746635437012)\n",
            "([128], 266, 0.8727015852928162)\n",
            "([128, 128], 0, 0.8783592581748962)\n",
            "([128, 128], 88, 0.9193776249885559)\n",
            "([128, 128], 177, 0.896746814250946)\n",
            "([128, 128], 266, 0.8599717020988464)\n",
            "([256, 128], 0, 0.9024045467376709)\n",
            "([256, 128], 88, 0.9123055338859558)\n",
            "([256, 128], 177, 0.8854314088821411)\n",
            "([256, 128], 266, 0.8599717020988464)\n",
            "([512, 128], 0, 0.8797736763954163)\n",
            "([512, 128], 88, 0.9250353574752808)\n",
            "([512, 128], 177, 0.8896746635437012)\n",
            "([512, 128], 266, 0.8599717020988464)\n",
            "([512, 256, 128], 0, 0.806223452091217)\n",
            "([512, 256, 128], 88, 0.908062219619751)\n",
            "([512, 256, 128], 177, 0.8868458271026611)\n",
            "([512, 256, 128], 266, 0.8628005385398865)\n",
            "([128, 256, 128], 0, 0.7779349088668823)\n",
            "([128, 256, 128], 88, 0.9052333831787109)\n",
            "([128, 256, 128], 177, 0.8854314088821411)\n",
            "([128, 256, 128], 266, 0.8599717020988464)\n"
          ]
        }
      ],
      "source": [
        "for r in results: print(r)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"plt.figure(figsize=(10,5))\\nplt.plot(history['loss'], alpha=.3, color='r', linestyle='--', linewidth=3)\\nplt.plot(history['val_loss'], label=MODEL_NAME, alpha=.8, color='r', linewidth=3)\\nplt.legend(loc='upper right', prop={'size': 18})\\nplt.title('Categorical Crossentropy', fontsize=20)\\nplt.grid(alpha=.3)\\n\\nplt.figure(figsize=(10,5))\\nplt.plot(history['accuracy'], alpha=.3, color='r', linestyle='--', linewidth=3)\\nplt.plot(history['val_accuracy'], label=MODEL_NAME, alpha=.8, color='r', linewidth=3)\\nplt.legend(loc='upper right', prop={'size': 18})\\nplt.title('Accuracy', fontsize=20)\\nplt.grid(alpha=.3)\\n\\nplt.show()\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"plt.figure(figsize=(10,5))\n",
        "plt.plot(history['loss'], alpha=.3, color='r', linestyle='--', linewidth=3)\n",
        "plt.plot(history['val_loss'], label=MODEL_NAME, alpha=.8, color='r', linewidth=3)\n",
        "plt.legend(loc='upper right', prop={'size': 18})\n",
        "plt.title('Categorical Crossentropy', fontsize=20)\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history['accuracy'], alpha=.3, color='r', linestyle='--', linewidth=3)\n",
        "plt.plot(history['val_accuracy'], label=MODEL_NAME, alpha=.8, color='r', linewidth=3)\n",
        "plt.legend(loc='upper right', prop={'size': 18})\n",
        "plt.title('Accuracy', fontsize=20)\n",
        "plt.grid(alpha=.3)\n",
        "\n",
        "plt.show()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'test_steps_per_epoch = np.math.ceil(test_gen.samples / test_gen.batch_size)\\n\\npredictions = model.predict(test_gen, steps=test_steps_per_epoch)'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"test_steps_per_epoch = np.math.ceil(test_gen.samples / test_gen.batch_size)\n",
        "\n",
        "predictions = model.predict(test_gen, steps=test_steps_per_epoch)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'predicted_classes = np.argmax(predictions, axis=-1)\\ntrue_classes = test_gen.classes\\nclass_labels = list(test_gen.class_indices.keys())'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"predicted_classes = np.argmax(predictions, axis=-1)\n",
        "true_classes = test_gen.classes\n",
        "class_labels = list(test_gen.class_indices.keys())\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"cm = confusion_matrix(true_classes, predicted_classes)\\n\\naccuracy = accuracy_score(true_classes, predicted_classes)\\nprecision = precision_score(true_classes, predicted_classes, average='macro')\\nrecall = recall_score(true_classes, predicted_classes, average='macro')\\nf1 = f1_score(true_classes, predicted_classes, average='macro')\\nprint('Accuracy:',accuracy.round(4))\\nprint('Precision:',precision.round(4))\\nprint('Recall:',recall.round(4))\\nprint('F1:',f1.round(4))\\n\\nplt.figure(figsize=(10,8))\\nsns.heatmap(cm.T, xticklabels=list(class_labels), yticklabels=class_labels)\\nplt.xlabel('True labels')\\nplt.ylabel('Predicted labels')\\nplt.show()\""
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "accuracy = accuracy_score(true_classes, predicted_classes)\n",
        "precision = precision_score(true_classes, predicted_classes, average='macro')\n",
        "recall = recall_score(true_classes, predicted_classes, average='macro')\n",
        "f1 = f1_score(true_classes, predicted_classes, average='macro')\n",
        "print('Accuracy:',accuracy.round(4))\n",
        "print('Precision:',precision.round(4))\n",
        "print('Recall:',recall.round(4))\n",
        "print('F1:',f1.round(4))\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm.T, xticklabels=list(class_labels), yticklabels=class_labels)\n",
        "plt.xlabel('True labels')\n",
        "plt.ylabel('Predicted labels')\n",
        "plt.show()\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.save(\"cnn_model\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "bb1e698a89a4f2271d8499a0cea708198ae2061802de8947e6d2bcfb50741015"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
